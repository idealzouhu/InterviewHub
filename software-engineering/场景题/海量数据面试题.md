### TOP K 问题

####  10 亿数据中找出最大的 10000 个

**问题描述：**10 亿数据中找出最大的 10000 个

**答案解析：**

**(1) 最小堆法**

小顶堆**适合维护固定大小的集合**，集合中的最小值始终在堆顶。具体步骤为：

1. 创建一个大小为 `10,000` 的小顶堆。
2. 遍历 10 亿个数据。如果当前数据比堆顶元素大，则将堆顶元素移出，并将当前数据插入堆中。
3. **遍历结束后，小顶堆中保存的就是最大的 10,000 个数据**。

空间复杂度为 $O(k)$， 时间复杂度为 $O(nlogk)$。在本题中，$k$  为 10000， $n$ 为 10 亿。

**(2) 优化思路——数据分块处理**

由于数据规模非常大（10亿），可以将数据分块处理，减少内存占用和单次计算复杂度。

具体步骤为：

1. 将数据分块（比如每块 1,000,000 条数据）。分块算法使用 Hash 算法

2. 每块数据内部用小顶堆找出局部最大的 10,000 个数据。

3. 将每块的结果汇总，使用小顶堆再次筛选，保留最终的 10,000 个数据。

这样做的优点有：

- **适合内存受限设备**：每次只需加载部分数据到内存，适合内存较小的设备。
- **多线程处理**：个partition交给一个线程处理，线程的处理逻辑可以采用最小堆，最后一个线程将结果归并。

**(3) 优化思路——数据去重**

在寻找数据集中最大的 k 个数时，如果数据中有大量重复值，直接对整个数据集（包括重复值）进行排序或堆处理，会浪费计算资源。

数据去重的方法有：

* **使用哈希表去重**。假设原始数据量为 n、去重后的数据量为m， 则去重时间复杂度为 $O(n)$， 堆操作时间复杂度为 $O(mlog⁡k)$， 总复杂度 $O(n+mlogk)$ <  $O(nlogk)$  (当数据去重后的规模 $m$ 远小于原始数据规模 $n$ 时, 优势显著)





#### 几亿淘宝日志中选出搜索热度最高的 10 个

**问题描述：**有几台机器存储着几亿淘宝搜索日志，你只有一台 2g 的电脑，怎么选出搜索热度最高的十个？

**答案解析：**

本题为 TOP K 问题中比较经典的文本问题。整体思路为

1. **分块处理：**利用分治法拆分数据。采用的是按关键词的首字母或次首字母拆分，保证数据在逻辑上互不交集。
2. **词频统计：**拆分后的每个小文件可以单独处理，统计其中每个关键词的出现频率。
3. **小顶堆排序：**依次处理每个文件，并逐渐更新最大的十个词

**(1) 分块处理**

由于单台机器内存有限，无法直接处理全部数据，需要先将数据集按一定规则拆分成多个小文件，每个文件只包含一部分数据。
这里采用的是 **按关键词的首字母或次首字母拆分**，保证数据在逻辑上互不交集。

**(2) 词频统计**

拆分后的每个小文件可以单独处理，统计其中每个关键词的出现频率。这一步可以使用以下两种方法：

- **哈希表**：使用哈希表（如 `HashMap`）记录关键词及其频率。
- **Trie 树**：使用 Trie 树存储所有关键词。在 Trie 树的节点中记录每个关键词的频率。

**(3) 小顶堆排序**

统计完成后，依次遍历每个小文件，找出频率最高的前 10 个关键词。



#### 超大文件中在有限的内存里找到单词频率

问题： 有 n （n>1000）多个文件，文件里存储了大量单词数据。如何快速统计每个独特单词出现的次数。  要求在读取过程中，能实时输出每个单词当前的数量。可以手动终止读取程序，终止后输出所有已统计到的单词数量。

解决措施有：

- HashMap 保存单词及其数量
- 多线程并发处理，使用 ConcurrentHashMap 保证线程安全性。
- 为了最大化线程的使用，可以将文件分块

问题进阶：返回出现频率最高的 100 个单词

- 使用小顶堆保存 HashMap 中频率出现最高的

[超大文件中在有限的内存里找到单词频率 top 100_1g内存,500g的文件,如何获取出现最多的单词-CSDN博客](https://blog.csdn.net/weixin_59287292/article/details/123242183)



#### 在不超过抓取限额的情况下使得抓取的网页价值之和最大

**问题描述：** 百度Spider如何在不超过抓取限额的情况下使得抓取的网页价值之和最大，要求一个最佳抓取方案。请详细描述你的算法思路（可以用伪代码），并分析时间复杂度和空间复杂度。

**[答案解析：](https://www.nowcoder.com/exam/test/85096610/submission?pid=134)**

(1) 问题分析

假设每个网页的价值为 $w_i$，消耗为 $c_i$。抓取限额为 $W$。网页数量规模 $n$ 。

(2) 求解算法

本题是一个经典的 **0-1 背包问题** 的变种

常见的求解方案为：

- **动态规划**。定义 $dp[j]$ 表示在抓取限额为 $j$ 的情况下，能够获得的最大网页价值。
- **排序 + 贪心算法**。

动态规划可以求全局最优解，贪心算法只能求局部最优解。

但是，在抓取限额 $C$ 非常大时，动态规划的时间复杂度 $O(n⋅C)$ 难以接受。然而，贪心算法的时间复杂度为  $O(nlog⁡n)$（排序时间）或者 $O(n)$（如果直接选择线性扫描的贪心策略）。同时，动态规划的空间复杂度 $O(C)$ 也很大。

因此**，本文使用排序 + 贪心算法。**

(3) 网页价值排序

- $w_i$ 的值为浮点数,  通过堆排序实现。

  - 使用一个**最大堆**存储网页的权值 $w_i$ 和消耗 $c_i$。

  - 每次从堆中取出当前价值最高的网页。

  - 如果网页的消耗 $c_i$ 超过剩余限额，则跳过该网页。

  - 如果可以抓取，更新剩余限额并累计总价值。

- $w_i$ 为整数,   则通过**桶式排序**记录每个价值对应的网页数量。
  - 创建一个桶数组，其中桶的索引代表网页的权值。
  - 遍历网页，将每个网页按照权值分配到对应的桶中，并记录每个桶中的网页数量。
  - 按照桶的索引（即权值）从高到低遍历，每次选择尽可能多的网页抓取，直到达到抓取限额。





### 海量数据判断存在

布隆过滤器可以快速判断海量数据是否存在。



### 海量数据排序

#### 非重复排序

**问题描述：**假设我们有一个不重复的整型序列 `{n1, n2, ..., nn}`，并且最大值为 `nmax`。

**答案解析：**

使用位图法，**利用位图法中 bit 的索引位置来表示原始数据中的元素**。具体步骤为：

1. **第一遍遍历整个序列**：在位图中对应的索引位置将出现的数字置为 `1`。例如，如果数字 `n1 = 5`，则位图数组的第 `5` 位置为 `1`。

2. **第二遍遍历位图**：根据位图中值为 `1` 的位置，依次输出对应的数字。这些 `1` 所在的索引值就是原始数据中的元素，这样就能按照大小关系排序输出。





#### 重复排序

**问题描述：**假设我们有一个重复的整型序列 `{n1, n2, ..., nn}`，并且最大值为 `nmax`。

**答案解析：**

对于包含重复数据的情况，**利用位图法中 bit 的索引位置来表示原始数据中的元素**，并使用额外的数组记录原始数据中元素重复出现的次数。

保留重复值：除了设置位图为 `1` 表示该值出现外，还可以记录该数字出现的次数。如果数字 5 出现了 3 次，可以在位图中相应的位置记录该数字的计数。输出时，根据计数值来决定该数字输出多少次。



### 海量数据查询

#### 统计活跃用户数量

**问题描述：**如何用redis存储统计1亿用户一年的登陆情况，并快速检索任意时间窗口内的活跃用户数量

**答案解析**：

使用 Redis 的 bitmap，每一个bitmap 存储所有用户在一天内的登录情况，单个 bitmap 中的每一个 bit 存储某个用户在某天的活跃状态。

**(1) 为什么使用 Bitmap**

- **存储效率高：**Bitmap 是一种基于位的存储结构，每位仅占 1 bit。对于 1 亿用户，按天存储每个用户是否登录：

  - 一天的数据只需 $1× 10^8$ 位，即约 **$12.5$ MB**。

  - 一年（365 天）的数据占用约 **$365×12.5=4.56$ GB** 内存，可以接受。

- **操作效率高**：Redis 提供了多种针对位图的高效操作命令（如 `SETBIT`, `GETBIT`, `BITCOUNT`, `BITOP` 等），时间复杂度较低，适合高性能需求。

**(2) 使用案例**

常用的 Redis Bitmap 操作有：

| **操作**                                     | **含义**                                                    | **时间复杂度** |
| -------------------------------------------- | ----------------------------------------------------------- | -------------- |
| **SETBIT key offset value**                  | 设置位图 key 中指定偏移量 offset 对应的位为 value（0 或 1） | O(1)           |
| **GETBIT key offset**                        | 获取位图 key 中指定偏移量 offset 对应的位的值（0 或 1）     | O(1)           |
| **BITCOUNT key**                             | 统计位图 key 中值为 1 的位数                                | O(N)           |
| **BITPOS key value**                         | 查找位图 key 中第一个值为 value（0 或 1）的位置             | O(N)           |
| **BITOP OR dest_key src_key1 src_key2 ...**  | 对多个位图进行按位 OR 操作，结果保存到 dest_key             | O(N)           |
| **BITOP AND dest_key src_key1 src_key2 ...** | 对多个位图进行按位 AND 操作，结果保存到 dest_key            | O(N)           |
| **BITOP XOR dest_key src_key1 src_key2 ...** | 对多个位图进行按位 XOR 操作，结果保存到 dest_key            | O(N)           |
| **BITOP NOT dest_key src_key**               | 对位图 src_key 进行按位 NOT 操作，结果保存到 dest_key       | O(N)           |

具体案例为：

- **设置用户活跃状态**：`setbit 2023-12-01 88000 1`： 表示在 2023 年 12 月 1 日，第 88000 个用户为活跃状态。时间复杂度为 O(1)

- **单用户查询**： `getbit 2023-12-01 88000`：查询第 88000 个用户在 2023 年 12 月 1 日是否活跃。

- **单天统计：**`bitcount 2023-12-01`：统计位图中值为 `1` 的位数，即某天的活跃用户数。

- **多天统计:**  统计 2023 年 12 月 1 日至 3 日内的活跃用户数量。

  ```
  bitop or result 2023-12-01 2023-12-02 2023-12-03
  bitcount result
  ```

  



### 参考资料

[海量数据处理常见问题](https://gitcode.com/doocs/advanced-java/overview)